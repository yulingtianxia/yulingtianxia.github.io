
 <!DOCTYPE HTML>
<html lang="zh-CN,en,default">
<head>
  <meta charset="UTF-8">
  
    <title>Implementing CNN with MPS | yulingtianxia&#39;s blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="杨萧玉">
    

    
    <meta name="description" content="最近一个月从零开始自学了下有关 iOS 上的机器学习相关知识，亲身实践了从数据采集到训练模型再到移动端预测的流程。理论知识学习路径为：机器学习-&amp;gt;深度学习-&amp;gt;迁移学习；实践框架学习路径为：TensorFlow-&amp;gt;Keras-&amp;gt;MPS(iOS 10)。最终完成一个简单的手势图像五分类问题，并预测 iOS 摄像头采集的图片。最终结果，训练集准确率 96.26%，交叉验证集准确率">
<meta property="og:type" content="article">
<meta property="og:title" content="Implementing CNN with MPS">
<meta property="og:url" content="http://yulingtianxia.com/blog/2017/05/30/Implementing-CNN-with-MPS/index.html">
<meta property="og:site_name" content="yulingtianxia's blog">
<meta property="og:description" content="最近一个月从零开始自学了下有关 iOS 上的机器学习相关知识，亲身实践了从数据采集到训练模型再到移动端预测的流程。理论知识学习路径为：机器学习-&amp;gt;深度学习-&amp;gt;迁移学习；实践框架学习路径为：TensorFlow-&amp;gt;Keras-&amp;gt;MPS(iOS 10)。最终完成一个简单的手势图像五分类问题，并预测 iOS 摄像头采集的图片。最终结果，训练集准确率 96.26%，交叉验证集准确率">
<meta property="og:image" content="http://wx3.sinaimg.cn/mw1024/642c5793ly1ff5ornniluj21kw0u3tn2.jpg">
<meta property="og:image" content="http://yulingtianxia.com/resources/MachineLearning/training_data.png">
<meta property="og:image" content="http://yulingtianxia.com/resources/MachineLearning/Inception V3.png">
<meta property="og:image" content="http://yulingtianxia.com/resources/MachineLearning/AnimatedFileQueues.gif">
<meta property="og:image" content="http://yulingtianxia.com/resources/MachineLearning/HDFView.jpg">
<meta property="og:image" content="https://github.com/shu223/iOS-10-Sampler/blob/master/README_resources/imagerecog.gif?raw=true">
<meta property="og:image" content="https://docs-assets.developer.apple.com/published/48ad0af3fd/b6d1d091-162c-418d-bc2e-0b6f3105c126.png">
<meta property="og:updated_time" content="2018-09-15T08:28:13.821Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Implementing CNN with MPS">
<meta name="twitter:description" content="最近一个月从零开始自学了下有关 iOS 上的机器学习相关知识，亲身实践了从数据采集到训练模型再到移动端预测的流程。理论知识学习路径为：机器学习-&amp;gt;深度学习-&amp;gt;迁移学习；实践框架学习路径为：TensorFlow-&amp;gt;Keras-&amp;gt;MPS(iOS 10)。最终完成一个简单的手势图像五分类问题，并预测 iOS 摄像头采集的图片。最终结果，训练集准确率 96.26%，交叉验证集准确率">
<meta name="twitter:image" content="http://wx3.sinaimg.cn/mw1024/642c5793ly1ff5ornniluj21kw0u3tn2.jpg">
<meta name="twitter:creator" content="@yulingtianxia">
<link rel="publisher" href="106642427004837273341">

    
    <link rel="alternative" href="/atom.xml" title="yulingtianxia&#39;s blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.png">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="yulingtianxia&#39;s blog" title="yulingtianxia&#39;s blog"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="yulingtianxia&#39;s blog">yulingtianxia&#39;s blog</a></h1>
				<h2 class="blog-motto">玉令天下的博客</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/tags">Tags</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="/search/index.html" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" autocomplete="off" name="q" maxlength="20" placeholder="Google" />
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/blog/2017/05/30/Implementing-CNN-with-MPS/" title="Implementing CNN with MPS" itemprop="url">Implementing CNN with MPS</a>
  </h1>
  <p class="article-author">By
       
		<a href="https://plus.google.com/106642427004837273341?rel=author" title="杨萧玉" target="_blank" itemprop="author">杨萧玉</a>
		
  <p class="article-time">
    <time datetime="2017-05-30T09:20:32.000Z" itemprop="datePublished"> 发表于 2017-05-30</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#理论基础"><span class="toc-number">1.</span> <span class="toc-text">理论基础</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#卷积神经网络简介"><span class="toc-number">1.1.</span> <span class="toc-text">卷积神经网络简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#图片分类常用的数据和预设网络模型"><span class="toc-number">1.2.</span> <span class="toc-text">图片分类常用的数据和预设网络模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#迁移学习"><span class="toc-number">1.3.</span> <span class="toc-text">迁移学习</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#框架选择"><span class="toc-number">2.</span> <span class="toc-text">框架选择</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据采集"><span class="toc-number">3.</span> <span class="toc-text">数据采集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Inception-V3-pre-trained-network"><span class="toc-number">4.</span> <span class="toc-text">Inception V3 pre-trained network</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#bottleneck-features"><span class="toc-number">4.1.</span> <span class="toc-text">bottleneck features</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Fine-tuning"><span class="toc-number">4.2.</span> <span class="toc-text">Fine-tuning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Convert-HDF5-to-binary-dat-files"><span class="toc-number">5.</span> <span class="toc-text">Convert HDF5 to binary .dat files</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Metal-Performance-Shaders"><span class="toc-number">6.</span> <span class="toc-text">Metal Performance Shaders</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#MPS-简介"><span class="toc-number">6.1.</span> <span class="toc-text">MPS 简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#使用-MPS-构建网络并预测"><span class="toc-number">6.2.</span> <span class="toc-text">使用 MPS 构建网络并预测</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-number">7.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number">8.</span> <span class="toc-text">Reference</span></a></li></ol>
		
		</div>
		
		<p>最近一个月从零开始自学了下有关 iOS 上的机器学习相关知识，亲身实践了从数据采集到训练模型再到移动端预测的流程。理论知识学习路径为：<strong>机器学习-&gt;深度学习-&gt;迁移学习</strong>；实践框架学习路径为：<strong>TensorFlow-&gt;Keras-&gt;MPS(iOS 10)</strong>。最终完成一个简单的手势图像五分类问题，并预测 iOS 摄像头采集的图片。最终结果，训练集准确率 96.26%，交叉验证集准确率 73.86%。</p>
<a id="more"></a>
<h2 id="理论基础"><a href="#理论基础" class="headerlink" title="理论基础"></a>理论基础</h2><p>虽然结果导向很重要，但是我还是想从基础学起，而不是去急于去网上找现成的解决方案来调参。毕竟我的目的是拓宽知识面，开新的技能树。</p>
<p>第一周从零开始学习了 Coursera 上 Stanford Ng 教授的 <a href="https://www.coursera.org/learn/machine-learning/home" target="_blank" rel="external">Machine Learning</a> 经典课程，用 Matlab 编写了一些 Demo，用一周时间完成了原本需要 11 周时间的所有课程和考试，对机器学习的基础知识有了掌握。</p>
<p><img src="http://wx3.sinaimg.cn/mw1024/642c5793ly1ff5ornniluj21kw0u3tn2.jpg" alt=""></p>
<p>机器学习大体可以分为有监督学习和无监督学习。带标签数据的有监督学习包含从最简单的线性回归到逻辑回归，再到神经网络和 SVM（支持向量机）。无监督学习包含大学竖直的 K-means 聚类，PCA(Principal Components Analysis) 降维。以及带标签数据的异常检测算法。为了确保机器学习的效果，需要通过看懂学习曲线决定下一步的工作，是解决 overfit 还是 underfit。使用交叉验证集和测试集评估模型时，如何平衡准确率和召回率，比如 F1 Score 指标。在数据预处理上要了解一些数据归一化标准化的方法。</p>
<p>光掌握机器学习的基础知识显然不够，大而全不如专而精。深度学习在图像识别领域大放异彩，其实深度学习是机器学习的一个分支，而深度学习领域最近在图像识别上应用最火的可能就是 CNN 了。所以在狂学深度学习的时候重点研究了下 CNN。</p>
<h3 id="卷积神经网络简介"><a href="#卷积神经网络简介" class="headerlink" title="卷积神经网络简介"></a>卷积神经网络简介</h3><p>全连接网络权重过多，而卷积神经网络可以实现权值共享，引入了深度，数据为 3D 的。推荐查看 Stanford 的 <a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="external">Convolutional Neural Networks (CNNs / ConvNets)</a>，中文翻译：<a href="https://zhuanlan.zhihu.com/p/22038289" target="_blank" rel="external">CS231n课程笔记翻译：卷积神经网络笔记</a>。</p>
<p>卷积核一般为奇数，常用的都是小卷积核，比如 1x1,3x3,5x5。<a href="https://zh.wikipedia.org/wiki/卷积" target="_blank" rel="external">卷积</a>是一种数学运算，卷积核在扫描数据的时候，正好做的就是卷积运算。卷积核其实就是个滤波器，通过平移点积运算处理数据。一个卷积层可以有多个卷积核，也就是多个滤波器，每种滤波器所『感受』的内容不同，结果也很有意思。可以看看这篇文章：<a href="https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html" target="_blank" rel="external">How convolutional neural networks see the world</a>。</p>
<p>CNN 中不仅有 Convolution，还有 Pooling，Activation，Fully Connected等层级。</p>
<p>Pooling 就是 downsampling，减小数据尺寸，常用的有有 max，average 等运算。<br>Activation 就是激活函数，常用的有 sigmoid，ReLU 等。<br>Fully Connected 也叫 Dense，因为全连接权重密度很大。其实就是个卷积核宽高等于输入数据宽高的特殊卷积层。卷积层和全连接层可以等效转换。</p>
<p>如果卷积核尺寸不是 1x1，或平移的步长不是 1x1，那么卷积运算后的结果肯定比原尺寸要小，所以padding 规则就很重要。一般常用的『Same』规则就是在数据周围填充一些 0，使得卷积运算后的数据宽和高跟输入数据一样。</p>
<h3 id="图片分类常用的数据和预设网络模型"><a href="#图片分类常用的数据和预设网络模型" class="headerlink" title="图片分类常用的数据和预设网络模型"></a>图片分类常用的数据和预设网络模型</h3><p>图片分类使用已经打好标签的数据库来进行有监督学习，</p>
<table>
<thead>
<tr>
<th style="text-align:center">Dataset</th>
<th style="text-align:center">Training Set Size</th>
<th style="text-align:center">Testing Set Size</th>
<th style="text-align:center">Number of Classes</th>
<th style="text-align:center">Comments</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="external">Cifar10</a></td>
<td style="text-align:center">60k</td>
<td style="text-align:center">10k</td>
<td style="text-align:center">10</td>
<td style="text-align:center">32x32 color</td>
</tr>
<tr>
<td style="text-align:center"><a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="external">MNIST</a></td>
<td style="text-align:center">60k</td>
<td style="text-align:center">10k</td>
<td style="text-align:center">10</td>
<td style="text-align:center">28x28 gray</td>
</tr>
<tr>
<td style="text-align:center"><a href="http://www.image-net.org/challenges/LSVRC/2012/" target="_blank" rel="external">ImageNet</a></td>
<td style="text-align:center">1.2M</td>
<td style="text-align:center">50k</td>
<td style="text-align:center">1000</td>
<td style="text-align:center">Various sizes</td>
</tr>
</tbody>
</table>
<p><a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="external">MNIST</a> 算是深度学习领域的 HelloWorld 了。</p>
<p><a href="https://www.cs.toronto.edu/%7Ekriz/cifar.html" target="_blank" rel="external">CIFAR</a> 小尺寸图片数据库，包含 CIFAR10 和 CIFAR100。</p>
<p>在图像识别领域，<a href="http://image-net.org" target="_blank" rel="external">ImageNet</a> 是非常有名的数据库，历年挑战中都有新的更复杂的神经网络跑出更好的结果。下面的表是一些网络模型在 <a href="http://image-net.org" target="_blank" rel="external">ImageNet</a> Challenge 中的准确率以及 TF-Slim 源码和 checkpoint 文件，数据来源：<a href="https://github.com/tensorflow/models/tree/master/slim" target="_blank" rel="external">TensorFlow-Slim image classification library</a></p>
<table>
<thead>
<tr>
<th style="text-align:center">Model</th>
<th style="text-align:center">TF-Slim File</th>
<th style="text-align:center">Checkpoint</th>
<th style="text-align:center">Top-1 Accuracy</th>
<th style="text-align:center">Top-5 Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><a href="http://arxiv.org/abs/1409.4842v1" target="_blank" rel="external">Inception V1</a></td>
<td style="text-align:center"><a href="https://github.com/tensorflow/models/blob/master/slim/nets/inception_v1.py" target="_blank" rel="external">Code</a></td>
<td style="text-align:center"><a href="http://download.tensorflow.org/models/inception_v1_2016_08_28.tar.gz" target="_blank" rel="external">inception_v1_2016_08_28.tar.gz</a></td>
<td style="text-align:center">69.8</td>
<td style="text-align:center">89.6</td>
<td></td>
</tr>
<tr>
<td style="text-align:center"><a href="http://arxiv.org/abs/1502.03167" target="_blank" rel="external">Inception V2</a></td>
<td style="text-align:center"><a href="https://github.com/tensorflow/models/blob/master/slim/nets/inception_v2.py" target="_blank" rel="external">Code</a></td>
<td style="text-align:center"><a href="http://download.tensorflow.org/models/inception_v2_2016_08_28.tar.gz" target="_blank" rel="external">inception_v2_2016_08_28.tar.gz</a></td>
<td style="text-align:center">73.9</td>
<td style="text-align:center">91.8</td>
<td></td>
</tr>
<tr>
<td style="text-align:center"><a href="http://arxiv.org/abs/1512.00567" target="_blank" rel="external">Inception V3</a></td>
<td style="text-align:center"><a href="https://github.com/tensorflow/models/blob/master/slim/nets/inception_v3.py" target="_blank" rel="external">Code</a></td>
<td style="text-align:center"><a href="http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz" target="_blank" rel="external">inception_v3_2016_08_28.tar.gz</a></td>
<td style="text-align:center">78.0</td>
<td style="text-align:center">93.9</td>
<td></td>
</tr>
<tr>
<td style="text-align:center"><a href="http://arxiv.org/abs/1602.07261" target="_blank" rel="external">Inception V4</a></td>
<td style="text-align:center"><a href="https://github.com/tensorflow/models/blob/master/slim/nets/inception_v4.py" target="_blank" rel="external">Code</a></td>
<td style="text-align:center"><a href="http://download.tensorflow.org/models/inception_v4_2016_09_09.tar.gz" target="_blank" rel="external">inception_v4_2016_09_09.tar.gz</a></td>
<td style="text-align:center">80.2</td>
<td style="text-align:center">95.2</td>
<td></td>
</tr>
<tr>
<td style="text-align:center"><a href="http://arxiv.org/abs/1602.07261" target="_blank" rel="external">Inception-ResNet-v2</a></td>
<td style="text-align:center"><a href="https://github.com/tensorflow/models/blob/master/slim/nets/inception_resnet_v2.py" target="_blank" rel="external">Code</a></td>
<td style="text-align:center"><a href="http://download.tensorflow.org/models/inception_resnet_v2_2016_08_30.tar.gz" target="_blank" rel="external">inception_resnet_v2.tar.gz</a></td>
<td style="text-align:center">80.4</td>
<td style="text-align:center">95.3</td>
<td></td>
</tr>
<tr>
<td style="text-align:center"><a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="external">ResNet V1 50</a></td>
<td style="text-align:center"><a href="https://github.com/tensorflow/models/blob/master/slim/nets/resnet_v1.py" target="_blank" rel="external">Code</a></td>
<td style="text-align:center"><a href="http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz" target="_blank" rel="external">resnet_v1_50.tar.gz</a></td>
<td style="text-align:center">75.2</td>
<td style="text-align:center">92.2</td>
<td></td>
</tr>
<tr>
<td style="text-align:center"><a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="external">ResNet V1 101</a></td>
<td style="text-align:center"><a href="https://github.com/tensorflow/models/blob/master/slim/nets/resnet_v1.py" target="_blank" rel="external">Code</a></td>
<td style="text-align:center"><a href="http://download.tensorflow.org/models/resnet_v1_101_2016_08_28.tar.gz" target="_blank" rel="external">resnet_v1_101.tar.gz</a></td>
<td style="text-align:center">76.4</td>
<td style="text-align:center">92.9</td>
<td></td>
</tr>
<tr>
<td style="text-align:center"><a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="external">ResNet V1 152</a></td>
<td style="text-align:center"><a href="https://github.com/tensorflow/models/blob/master/slim/nets/resnet_v1.py" target="_blank" rel="external">Code</a></td>
<td style="text-align:center"><a href="http://download.tensorflow.org/models/resnet_v1_152_2016_08_28.tar.gz" target="_blank" rel="external">resnet_v1_152.tar.gz</a></td>
<td style="text-align:center">76.8</td>
<td style="text-align:center">93.2</td>
<td></td>
</tr>
<tr>
<td style="text-align:center"><a href="https://arxiv.org/abs/1603.05027" target="_blank" rel="external">ResNet V2 50</a>^</td>
<td style="text-align:center"><a href="https://github.com/tensorflow/models/blob/master/slim/nets/resnet_v2.py" target="_blank" rel="external">Code</a></td>
<td style="text-align:center"><a href="http://download.tensorflow.org/models/resnet_v2_50_2017_04_14.tar.gz" target="_blank" rel="external">resnet_v2_50.tar.gz</a></td>
<td style="text-align:center">75.6</td>
<td style="text-align:center">92.8</td>
<td></td>
</tr>
<tr>
<td style="text-align:center"><a href="https://arxiv.org/abs/1603.05027" target="_blank" rel="external">ResNet V2 101</a>^</td>
<td style="text-align:center"><a href="https://github.com/tensorflow/models/blob/master/slim/nets/resnet_v2.py" target="_blank" rel="external">Code</a></td>
<td style="text-align:center"><a href="http://download.tensorflow.org/models/resnet_v2_101_2017_04_14.tar.gz" target="_blank" rel="external">resnet_v2_101.tar.gz</a></td>
<td style="text-align:center">77.0</td>
<td style="text-align:center">93.7</td>
<td></td>
</tr>
<tr>
<td style="text-align:center"><a href="https://arxiv.org/abs/1603.05027" target="_blank" rel="external">ResNet V2 152</a>^</td>
<td style="text-align:center"><a href="https://github.com/tensorflow/models/blob/master/slim/nets/resnet_v2.py" target="_blank" rel="external">Code</a></td>
<td style="text-align:center"><a href="http://download.tensorflow.org/models/resnet_v2_152_2017_04_14.tar.gz" target="_blank" rel="external">resnet_v2_152.tar.gz</a></td>
<td style="text-align:center">77.8</td>
<td style="text-align:center">94.1</td>
<td></td>
</tr>
<tr>
<td style="text-align:center"><a href="http://arxiv.org/abs/1409.1556.pdf" target="_blank" rel="external">VGG 16</a></td>
<td style="text-align:center"><a href="https://github.com/tensorflow/models/blob/master/slim/nets/vgg.py" target="_blank" rel="external">Code</a></td>
<td style="text-align:center"><a href="http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz" target="_blank" rel="external">vgg_16.tar.gz</a></td>
<td style="text-align:center">71.5</td>
<td style="text-align:center">89.8</td>
<td></td>
</tr>
<tr>
<td style="text-align:center"><a href="http://arxiv.org/abs/1409.1556.pdf" target="_blank" rel="external">VGG 19</a></td>
<td style="text-align:center"><a href="https://github.com/tensorflow/models/blob/master/slim/nets/vgg.py" target="_blank" rel="external">Code</a></td>
<td style="text-align:center"><a href="http://download.tensorflow.org/models/vgg_19_2016_08_28.tar.gz" target="_blank" rel="external">vgg_19.tar.gz</a></td>
<td style="text-align:center">71.1</td>
<td style="text-align:center">89.8</td>
<td></td>
</tr>
</tbody>
</table>
<p>推荐一个还算不错的机器学习的数据网站：<a href="https://www.kaggle.com" target="_blank" rel="external">kaggle</a></p>
<h3 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h3><p>从头开始训练一个复杂的网络是很费时费力的，需要获取符合目标的海量真实数据，并使用性能极强的集群来训练数据，并有足够的耐心等待训练结果。稍有不慎，还需要不断调参，重新再来。这是个枯燥乏味的体力活，并且是在有硬件经济实力的基础上才办得到的。总会看到一些论文里描述自己的模型用 Tesla KXX 跑了多久才训练出了结果，其实在机器学习领域，花费半年甚至更久的时间来调参优化模型是很正常的。</p>
<p>所以基于已经训练好的模型参数来进行 fine-tuning 后应用到新的模型上是一个省时省力的方案，也被称之为迁移学习。大部分数据是存在相关性的，在图片分类问题中，即便现有模型不包含我们想要的分类，也可以利用已经训练好的权重来进行 fine-tuning，使其对新的类别进行分类。</p>
<p>一般的做法是将已经训练好的模型权重加载，除去 top 部分（全连接层和 softmax 分类器等），冻结前面层级的权重，只保留想要 fine-tuning 的层级（一般是后面的卷积层），最后根据分类个数自己添加全连接层。训练时只有后面的层级权重才会被修改，前面已经训练好的权重不会改变。这样会很快将正确率提高到 90% 以上。</p>
<p>详细内容可以参考这篇文章：(<a href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html" target="_blank" rel="external">https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html</a>)</p>
<h2 id="框架选择"><a href="#框架选择" class="headerlink" title="框架选择"></a>框架选择</h2><p>有一些知名的框架可供选择：TensorFlow, Torch, Caffee, Theano, Keras…</p>
<p>不同框架所使用的数据格式不一样，主要区别在于 Channel  通道的位置是在最前还是最后。框架之间的学习成本都不一样，单拿 TensorFlow 来说，其最基础的语法需要一点点构建一张图，而其 <code>tf.contrib.learn</code> 和 <code>tf.contrib.layers</code> API 是更高一层的封装，还有 TF-Slim 这种更轻量级的高级封装，几行代码就能干好多事，看起来更屌。但其实目前由于 TensorFlow 的快速迭代，导致不能向下兼容，老代码运行不起来。单拿 TF-Slim 来说，官网 API 文档缺失，Github 的教程代码老旧无法运行，还在使用从 model 库 merge 到 tensorflow 之前的语法。我当时本想用 TF-Slim 快速验证一些模型，结果没想到反而浪费了大量时间，得不偿失。</p>
<p>Keras 基于 TensorFlow 或 Theano，集成了大量功能，是一种方便快速验证 idea 的高层 API。 内置大量常用网络，很容易上手，语法简洁，功能强大又不失可定制性。强力推荐，官方文档：<a href="https://keras.io" target="_blank" rel="external">Keras Documentation</a>，中文文档：<a href="http://keras-cn.readthedocs.io/en/latest/" target="_blank" rel="external">Keras 中文文档</a></p>
<p>无论是哪种框架，几乎都是基于分布式设计的思想，先描述出计算图，然后再向图中填充数据流，使其运转起来，最后得到结果。虽然是使用 Python 语言来描述计算图，但是真正繁重的工作都会提交给底层的后端去处理。但这样也给 debug 带来了困难，因为描述计算图的时候并不能得到数据结果，只能检查出数据格式是否匹配。</p>
<blockquote>
<p>笼统的说，符号主义的计算首先定义各种变量，然后建立一个“计算图”，计算图规定了各个变量之间的计算关系。建立好的计算图需要编译以确定其内部细节，然而，此时的计算图还是一个“空壳子”，里面没有任何实际的数据，只有当你把需要运算的输入放进去后，才能在整个模型中形成数据流，从而形成输出值。<br>    就像用管道搭建供水系统，当你在拼水管的时候，里面是没有水的。只有所有的管子都接完了，才能送水。<br>    – 引自 <a href="http://keras-cn.readthedocs.io/en/latest/for_beginners/concepts/" target="_blank" rel="external">http://keras-cn.readthedocs.io/en/latest/for_beginners/concepts/</a></p>
</blockquote>
<h2 id="数据采集"><a href="#数据采集" class="headerlink" title="数据采集"></a>数据采集</h2><p>因为网上提供的一些用于训练的海量图片数据都是格式整齐像素较低的图片，比如28x28这种，且特征明显，都为某种物体，这种专用于比赛挑战的图片分类数量一般都是10，100，1000等，更专注于算法的准确率，忽视了真实的场景。</p>
<p>为了模拟真实场景，我使用 Web 程序调用 iMac 前置摄像头采集 320x240 尺寸的照片。为了更高效采集图片数据，我采用连拍的方式拍摄并保存图片到本地：</p>
<p><img src="http://yulingtianxia.com/resources/MachineLearning/training_data.png" alt="帅是我的无奈"></p>
<p>需要去除少量过于模糊和手指不小心跑出屏幕外的图片，尽可能提高数据的质量。</p>
<p>因为不同平台和浏览器对 Html5 规范支持程度不同，建议在 Mac 上使用 Firefox，Windows 上应该 Chrome 也好使，但没试过。</p>
<p>图像采集的代码放在 <a href="https://github.com/yulingtianxia/HandGestureCNN/tree/master/captureImages" target="_blank" rel="external">captureImages</a> 目录里。</p>
<h2 id="Inception-V3-pre-trained-network"><a href="#Inception-V3-pre-trained-network" class="headerlink" title="Inception V3 pre-trained network"></a>Inception V3 pre-trained network</h2><p>在 Keras Blog 中，<a href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html" target="_blank" rel="external">Building powerful image classification models using very little data</a> 很好地介绍了如何针对小数据集利用现有的 VGG16 网络 fine-tuning，并在 <a href="https://www.kaggle.com/c/dogs-vs-cats/data" target="_blank" rel="external">Dogs vs. Cats</a> 数据集上取得了 94% 的准确率。</p>
<p>VGG 系列网络虽然结构简单易理解，但无论是加载权重的耗时还是预测耗时都要比 Inception 系列网络要长，这是因为其权重数据更多。虽然 Inception 系列更复杂，但鉴于其优秀的性能和更胜一筹的准确率，我决定在移动设备上使用 Inception 而非 VGG。</p>
<p>其实苹果爸爸已经帮我们用 Swift 和 Metal Performance Shaders 实现了个使用 Inception V3 网络预测图像类别的 Demo:<a href="https://developer.apple.com/library/content/samplecode/MetalImageRecognition/Introduction/Intro.html" target="_blank" rel="external">MetalImageRecognition: Performing Image Recognition with Inception_v3 Network using Metal Performance Shaders Convolutional Neural Network routines</a></p>
<p>所以我决定使用 <a href="https://arxiv.org/pdf/1512.00567v3.pdf" target="_blank" rel="external">Inception V3 Network</a> 来 fine-tuning，这样在后续的 MPS 代码编写上就会省很多时间。TensorFlow 官方也有相应 <a href="https://www.tensorflow.org/tutorials/image_recognition#image-recognition" target="_blank" rel="external">教程</a>。</p>
<h3 id="bottleneck-features"><a href="#bottleneck-features" class="headerlink" title="bottleneck features"></a>bottleneck features</h3><p>下图展示了 Inception V3 网络的结构，其中的 top 部分就是 Final part 所指的部分，我们可以将其替换成我们自己的全连接层，利用前面 Input 预测的结果来作为输入数据，训练我们自己的分类器。</p>
<p><img src="http://yulingtianxia.com/resources/MachineLearning/Inception V3.png" alt=""></p>
<blockquote>
<p>上图中的 Inception mudules 使用的是<a href="https://arxiv.org/pdf/1512.00567v3.pdf" target="_blank" rel="external">论文</a>中提到的图 6 的结构，实际代码中则使用的图 5。</p>
</blockquote>
<p>Keras 有很多使用 ImageNet 预训练的模型，我们这里只需要 Inception V3 去掉 Final part 的剩余部分，一行代码搞定：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">model</span> = applications.InceptionV3(include_top=<span class="literal">False</span>, weights=<span class="string">'imagenet'</span>)</span><br></pre></td></tr></table></figure>
<p>在 TensorFlow 中读取文件数据需要通过 <code>QueueRunner</code> 和 <code>Coordinator</code> 构造队列来实现 data flow，比较麻烦：</p>
<p><img src="http://yulingtianxia.com/resources/MachineLearning/AnimatedFileQueues.gif" alt="图片来源 TensorFlow"></p>
<p>Keras 真是太方便了，用生成器把图片数据标准化，使用加载好的 <code>model</code> 预测出结果，并保存到 npy 文件中。</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">datagen</span> = ImageDataGenerator(<span class="attr">rescale=1.</span> / <span class="number">255</span>)</span><br><span class="line"><span class="attr">generator</span> = datagen.flow_from_directory(</span><br><span class="line">   train_data_dir,</span><br><span class="line">   <span class="attr">target_size=(img_width,</span> img_height),</span><br><span class="line">   <span class="attr">batch_size=batch_size,</span></span><br><span class="line">   <span class="attr">class_mode=None,</span></span><br><span class="line">   <span class="attr">shuffle=False)</span></span><br><span class="line"><span class="attr">bottleneck_features_train</span> = model.predict_generator(</span><br><span class="line">   generator, nb_train_samples // batch_size)</span><br><span class="line">np.save(open('bottleneck_features_train.npy', 'w'),</span><br><span class="line">       bottleneck_features_train)</span><br></pre></td></tr></table></figure>
<p>这里保存的结果并不是 one-hot 格式的分类结果，只是作为 Final part 的输入，所以叫做 bottleneck features。</p>
<p>下一步就是构建自己的 Final part，比如我们这里想要做个五分类的模型：</p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">model</span> = Sequential()</span><br><span class="line"><span class="keyword">model</span>.add(Flatten(input_shape=train_data.shape[<span class="number">1</span>:]))</span><br><span class="line"><span class="keyword">model</span>.add(Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line"><span class="keyword">model</span>.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line"><span class="keyword">model</span>.add(Dense(<span class="number">5</span>, activation=<span class="string">'softmax'</span>))</span><br></pre></td></tr></table></figure>
<p><code>Flatten</code> 和 <code>Dropout</code> 层并不会改变数据，是没有权重的层。所以这里有两个全连接层，最后一层有五个节点，输出一个长度为 5 的 one-hot 格式向量。</p>
<p>这里之所以使用 bottleneck features 作为输入数据来进行训练，是为了节省运算资源。如果采用冻结前面部分网络的方式，虽然被冻结的网络权重不会变，但每跑一次的运算量都很大，而且结果是相同的。所以采取预测一次 bottleneck features，离线保存的方式。在机器学习中减少 loss 提升准确率常用的方法就是梯度下降法，实际应用中使用 mini-batch 梯度下降法来平衡计算性能和 loss 收敛效果。这里的 batch_size 就是每次下降所使用数据批次的数量。</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model.compile(<span class="attr">optimizer=optimizers.SGD(lr=1e-4,</span> <span class="attr">momentum=0.9),</span></span><br><span class="line">             <span class="attr">loss='categorical_crossentropy',</span> <span class="attr">metrics=['accuracy'])</span></span><br><span class="line"></span><br><span class="line">model.fit(train_data, train_labels,</span><br><span class="line">         <span class="attr">epochs=epochs,</span></span><br><span class="line">         <span class="attr">batch_size=batch_size,</span></span><br><span class="line">         <span class="attr">validation_data=(validation_data,</span> validation_labels))</span><br><span class="line">model.save_weights(top_model_weights_path)</span><br></pre></td></tr></table></figure>
<p>这里训练的是我们自己添加的两个全连接层，以便于拟合我们自己的数据。</p>
<p>这部分的源码放在 <a href="https://github.com/yulingtianxia/HandGestureCNN/blob/master/Train/bottleneck_features_train_inceptionv3.py" target="_blank" rel="external">bottleneck_features_train_inceptionv3.py</a></p>
<h3 id="Fine-tuning"><a href="#Fine-tuning" class="headerlink" title="Fine-tuning"></a>Fine-tuning</h3><p>为了达到更好的效果，可以解冻后面几层。看了下 Inception V3 的网络结构，最后一个 tower 拥有 9 个卷积层，比较复杂。虽然理论上 fine-tuneing 整个 tower 是可行的，但是计算开销很大，用我的 iMac 4 GHz Intel Core i7 八核跑一个月都不行。</p>
<p>现在需要加载预训练网络的权重到 <code>base_model</code> 中，并将其与 <code>top_model</code> 拼在一起。Keras 中有两种描述模型，一种是 <code>Sequential</code>，另一种是带有函数式 API 的 <code>Model</code>。前者层与层之前连接的入度和出度都为 1，后者就很灵活很随意了。这里构建 <code>top_model</code> 使用的 <code>Sequential</code>，然后使用 <code>Model</code> 统一输入和输出，起到连接的作用。最后通过设置 <code>trainable</code> 属性来冻结部分网络。为了让准确率更高，会将上一步 bottleneck features 训练好的权重作为 <code>top_model</code> 的初始权重。</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># build the InceptionV3 network</span></span><br><span class="line"><span class="attr">input_tensor</span> = Input(<span class="attr">shape=(img_height,</span> img_width, <span class="number">3</span>))</span><br><span class="line"><span class="attr">base_model</span> = applications.InceptionV3(<span class="attr">weights='imagenet',</span> <span class="attr">include_top=False,</span> <span class="attr">input_tensor=input_tensor)</span></span><br><span class="line">print('Model loaded.')</span><br><span class="line"></span><br><span class="line"><span class="comment"># build a classifier model to put on top of the convolutional model</span></span><br><span class="line"><span class="attr">top_model</span> = Sequential()</span><br><span class="line">top_model.add(Flatten(<span class="attr">input_shape=base_model.output_shape[1:]))</span></span><br><span class="line">top_model.add(Dense(<span class="number">256</span>, <span class="attr">activation='relu'))</span></span><br><span class="line">top_model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">top_model.add(Dense(<span class="number">5</span>, <span class="attr">activation='softmax'))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># note that it is necessary to start with a fully-trained</span></span><br><span class="line"><span class="comment"># classifier, including the top classifier,</span></span><br><span class="line"><span class="comment"># in order to successfully do fine-tuning</span></span><br><span class="line">top_model.load_weights(top_model_weights_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># add the model on top of the convolutional base</span></span><br><span class="line"><span class="attr">model</span> = Model(<span class="attr">inputs=base_model.input,</span> <span class="attr">outputs=top_model(base_model.output))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># set the first xx layers (up to the last conv block)</span></span><br><span class="line"><span class="comment"># to non-trainable (weights will not be updated)</span></span><br><span class="line"></span><br><span class="line">for layer <span class="keyword">in</span> model.layers[:len(base_model.layers)-<span class="number">5</span>]:</span><br><span class="line">    layer.<span class="attr">trainable</span> = False</span><br></pre></td></tr></table></figure>
<p>有关 Keras 两种模型的概念可以查看 <a href="https://keras.io/models/about-keras-models/" target="_blank" rel="external">About Keras models</a>。</p>
<p>可以通过设置数据生成器的一些参数来提升数据的随机性，降低过拟合。<code>ImageDataGenerator</code> 针对图片有很多预设的处理方式，例如平移，旋转，缩放，反转等。TensorFlow 中也有类似的图片预处理功能，但 API 使用上没 Keras 便利。有关图片预处理的内容可以参考文档 <a href="https://keras.io/preprocessing/image/" target="_blank" rel="external">Image Preprocessing</a>，这里仅针对某些方式进行随意预处理，提升数据：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">train_datagen</span> = ImageDataGenerator(</span><br><span class="line">	<span class="attr">rescale=1./255,</span></span><br><span class="line">  	<span class="attr">rotation_range=40,</span></span><br><span class="line">  	<span class="attr">width_shift_range=0.2,</span></span><br><span class="line">  	<span class="attr">height_shift_range=0.2,</span></span><br><span class="line">  	<span class="attr">shear_range=0.2,</span></span><br><span class="line">  	<span class="attr">zoom_range=0.2,</span></span><br><span class="line">  	<span class="attr">horizontal_flip=True,</span></span><br><span class="line">  	<span class="attr">fill_mode='nearest')</span></span><br></pre></td></tr></table></figure>
<p>Keras 可以根据数据的文件夹自动分类打标签，所以我将图片按文件夹归类就可以了，很方便。</p>
<p>我一共使用了 1808 张图片作为训练集，192 张图片作为交叉验证集。经过了 50 个 epoch 后，训练集准确率 96.26%，交叉验证集准确率 73.86%。</p>
<p>这部分源码放在 <a href="https://github.com/yulingtianxia/HandGestureCNN/blob/master/Train/finetune_inceptionv3.py" target="_blank" rel="external">finetune_inceptionv3.py</a></p>
<h2 id="Convert-HDF5-to-binary-dat-files"><a href="#Convert-HDF5-to-binary-dat-files" class="headerlink" title="Convert HDF5 to binary .dat files"></a>Convert HDF5 to binary .dat files</h2><blockquote>
<p>HDF（英语：Hierarchical Data Format）指一种为存储和处理大容量科学数据设计的文件格式及相应库文件。HDF最早由NCSA开发，目前在非盈利组织 HDF 小组维护下继续发展。当前流行的版本是HDF5。<br>    – 维基百科</p>
</blockquote>
<p><a href="https://www.hdfgroup.org" target="_blank" rel="external">HDF Group</a> 提供了可视化查看 HDF 文件的工具：<a href="https://support.hdfgroup.org/products/java/release/download.html" target="_blank" rel="external">HDFView</a>，因为是用 java 写的，所以是跨平台的。Mac 版本有个已知的 bug：双击一个 <code>.h5</code> 文件后 HDFView 界面是空的，需要把 <code>.h5</code> 文件拖动到 HDFView 左边栏才能打开。</p>
<p><img src="http://yulingtianxia.com/resources/MachineLearning/HDFView.jpg" alt=""></p>
<p>Keras 可以将训练处的权重结果高存成 HDF5 格式，但苹果提供的 Demo 使用的权重文件是 memory-mapped 二进制文件，每层网络都对应一个 <code>.dat</code> 文件。</p>
<p><a href="https://support.hdfgroup.org/products/hdf5_tools/index.html" target="_blank" rel="external">SOFTWARE USING HDF5</a> 列举了很多用于操作 HDF 文件和格式转换的工具。可以用一些工具将存有权重的 HDF 文件先转化成若干 <code>.dat</code> 文件，然后再打包到 iOS App 中。还有一种做法是将 HDF 文件打包到 iOS App 中，然后在客户端完成格式导出。<a href="https://github.com/aleph7/HDF5Kit" target="_blank" rel="external">HDF5Kit</a> 是对 <a href="https://support.hdfgroup.org/ftp/HDF5/releases/hdf5-1.10/" target="_blank" rel="external">HDF 源码</a>的 Swift 封装，不过还有些 crash。我采用了第二种做法，因为我懒，替换权重文件的时候只需要一个 HDF 文件，不用替换一堆 <code>.dat</code> 文件🙄。实际应用中千万别这么干。</p>
<p>可以根据上图中 HDFView 展示的树状层级递归遍历 Group，并拼接好正确的名称。比如 “bias:0” 和 “kernel:0”。将 HDF5 转换成二进制文件的代码如下：</p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Read parameters from HDF5 file and store to dat file in Tmp directory</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">extractHDF5</span><span class="params">(h5Name: String)</span></span> &#123;</span><br><span class="line">    <span class="comment">// MARK: Parse HDF5 file</span></span><br><span class="line">    <span class="keyword">guard</span> <span class="keyword">let</span> path = <span class="type">Bundle</span>.main.path(forResource: h5Name, ofType: <span class="string">"h5"</span>) <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">fatalError</span>(<span class="string">"Failed to get a path"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">guard</span> <span class="keyword">let</span> file = <span class="type">File</span>.open(path, mode: .readOnly) <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">fatalError</span>(<span class="string">"Failed to open file at <span class="subst">\(path)</span>"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">guard</span> <span class="keyword">let</span> layerNamesStringAttribute = file.openStringAttribute(<span class="string">"layer_names"</span>) <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">fatalError</span>(<span class="string">"Failed to open attribute 'layer_names'"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">guard</span> <span class="keyword">let</span> layerNames = <span class="keyword">try</span>? layerNamesStringAttribute.read() <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">fatalError</span>(<span class="string">"Failed to get layer names"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// count used for file name later</span></span><br><span class="line">    <span class="keyword">var</span> countOfConvLayer = <span class="number">0</span></span><br><span class="line">    <span class="keyword">var</span> countOfFcLayer   = <span class="number">0</span></span><br><span class="line">    <span class="keyword">var</span> partOfFileName = <span class="string">""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> layerName <span class="keyword">in</span> layerNames &#123;</span><br><span class="line">        <span class="keyword">guard</span> <span class="keyword">let</span> layerGroup = file.openGroup(layerName) <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="built_in">fatalError</span>(<span class="string">"Failed to open group of <span class="subst">\(layerName)</span>"</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> objectName <span class="keyword">in</span> layerGroup.objectNames() &#123;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// only the layer that has parameters remain</span></span><br><span class="line">            <span class="keyword">guard</span> <span class="keyword">let</span> wtDataset = layerGroup.openFloatDataset(objectName + <span class="string">"/kernel:0"</span>) <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="built_in">fatalError</span>(<span class="string">"Failed to open data set of <span class="subst">\(objectName)</span>/kernel:0"</span>)</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">guard</span> <span class="keyword">let</span> bsDataset = layerGroup.openFloatDataset(objectName + <span class="string">"/bias:0"</span>) <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="built_in">fatalError</span>(<span class="string">"Failed to open data set of <span class="subst">\(objectName)</span>/bias:0"</span>)</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">var</span> dimension = wtDataset.space.dims</span><br><span class="line">            <span class="keyword">guard</span> <span class="keyword">var</span> wtArray = <span class="keyword">try</span>? wtDataset.read() <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="built_in">fatalError</span>(<span class="string">"Failed to read data set of <span class="subst">\(objectName)</span>/kernel:0"</span>)</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">guard</span> <span class="keyword">var</span> bsArray = <span class="keyword">try</span>? bsDataset.read() <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="built_in">fatalError</span>(<span class="string">"Failed to read data set of <span class="subst">\(objectName)</span>/bias:0"</span>)</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">let</span> wtLength = wtArray.<span class="built_in">count</span></span><br><span class="line">            <span class="keyword">let</span> bsLength = bsArray.<span class="built_in">count</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> dimension.<span class="built_in">count</span> == <span class="number">4</span> &#123;</span><br><span class="line">                <span class="comment">// weights for convolution layer</span></span><br><span class="line">                wtArray = <span class="type">SwapAxes</span>.for4dFlatArray(originalArray: wtArray, axis1: <span class="number">2</span>, axis2: <span class="number">3</span>, dimensionOfArray: &amp;dimension)</span><br><span class="line">                wtArray = <span class="type">SwapAxes</span>.for4dFlatArray(originalArray: wtArray, axis1: <span class="number">1</span>, axis2: <span class="number">2</span>, dimensionOfArray: &amp;dimension)</span><br><span class="line">                wtArray = <span class="type">SwapAxes</span>.for4dFlatArray(originalArray: wtArray, axis1: <span class="number">0</span>, axis2: <span class="number">1</span>, dimensionOfArray: &amp;dimension)</span><br><span class="line">                </span><br><span class="line">                countOfConvLayer += <span class="number">1</span></span><br><span class="line">                partOfFileName = <span class="string">"conv"</span> + <span class="type">String</span>(countOfConvLayer)</span><br><span class="line">                </span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> dimension.<span class="built_in">count</span> == <span class="number">2</span> &#123;</span><br><span class="line">                <span class="comment">// weights for fully connected layer</span></span><br><span class="line">                wtArray = <span class="type">SwapAxes</span>.for2dFlatArray(originalArray: wtArray, axis1: <span class="number">0</span>, axis2: <span class="number">1</span>, dimensionOfArray: &amp;dimension)</span><br><span class="line">                </span><br><span class="line">                countOfFcLayer += <span class="number">1</span></span><br><span class="line">                partOfFileName = <span class="string">"fc"</span> + <span class="type">String</span>(countOfFcLayer)</span><br><span class="line">                </span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="built_in">fatalError</span>(<span class="string">"Dataset's dimension is neither 4 (convolution layer) nor 2 (fully connected layer)"</span>)</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">let</span> wtData = <span class="type">NSData</span>(bytes: &amp;wtArray, length: wtLength * <span class="type">MemoryLayout</span>&lt;<span class="type">Float</span>&gt;.size)</span><br><span class="line">            <span class="keyword">let</span> bsData = <span class="type">NSData</span>(bytes: &amp;bsArray, length: bsLength * <span class="type">MemoryLayout</span>&lt;<span class="type">Float</span>&gt;.size)</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 写入数据到文件...</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Metal-Performance-Shaders"><a href="#Metal-Performance-Shaders" class="headerlink" title="Metal Performance Shaders"></a>Metal Performance Shaders</h2><h3 id="MPS-简介"><a href="#MPS-简介" class="headerlink" title="MPS 简介"></a>MPS 简介</h3><p>Metal Performance Shaders 简称 MPS，可以为使用 Metal 技术的 App 提供底层高性能 GPU 运算接口。最初苹果提供的 Shader 语言本来是很底层很生涩的，后来为 iOS 提供了原生支持的 API，可以用 Swift 或 OC 来调用底层接口了。iOS 9 的 MPS 提供了图片特效处理和 Metal 纹理相关的 API，iOS 10 的 MPS 新增了有关 CNN 和矩阵乘法的 API。不过目前苹果只开放了 CNN 的预测功能，如果想要在 iOS 10 上训练一个 CNN，那就只能借助第三方工具了。</p>
<p>苹果的 BNNS 同样提供了创建 CNN 的 API，而且也只能使用训练好的权重进行预测。但仅仅是对 CPU 进行了优化。因为 OpenGL 的限制，其性能与 Metal 相比并不占优势。OpenCL 在 iOS 上是私有框架。所以说目前看来，不考虑系统兼容性(iOS 10)和资源限制(arm64)，Metal 技术是发挥 GPU 运算优势的最好选择。</p>
<p>MPS 系统原生支持不用担心安装包增量问题，并且使用 Metal 技术使用 GPU 加速运算，功耗发热少。MPS 目前的缺点是不支持网络的训练和必须 HardCode 网络结构，但面对复杂度较低的神经网络时还是很实用的。毕竟 TensorFlow 在 iOS 上只能用 CPU 计算，且编译费时费力，安装包增量巨大。</p>
<p>MPS 在我的 iPhone 6s Plus 上性能很好，发热也少，可以通过神经网络实时预测出结果。这是 <a href="https://github.com/shu223/iOS-10-Sampler" target="_blank" rel="external">iOS-10-Sampler</a> 项目的效果，它是在苹果官方 Demo <a href="https://developer.apple.com/library/content/samplecode/MetalImageRecognition/Introduction/Intro.html" target="_blank" rel="external">MetalImageRecognition</a> 基础上稍微改进拍摄功能的用户体验，MPS 的部分未做任何改动。我基于它和 <a href="https://github.com/kazoo-kmt/MPSCNNfeeder" target="_blank" rel="external">MPSCNNfeeder</a> 实现了 <a href="https://github.com/yulingtianxia/HandGestureCNN/tree/master/HandGestureCNN" target="_blank" rel="external">HandGestureCNN</a>。</p>
<p><img src="https://github.com/shu223/iOS-10-Sampler/blob/master/README_resources/imagerecog.gif?raw=true" alt=""></p>
<p>苹果给了一个 MPS 的 HelloWorld： <a href="https://developer.apple.com/library/content/samplecode/MPSCNNHelloWorld/Introduction/Intro.html" target="_blank" rel="external">MPSCNNHelloWorld: Simple Digit Detection Convolution Neural Networks (CNN)</a>，恰好对应着机器学习领域的 HelloWorld MNIST。可以通过查看这个 Demo 的源码来快速上手 MPS 的用法。</p>
<p>其实总体来说并不是很复杂，但有几个重要的地方需要我们自己去解决：</p>
<ol>
<li>数据处理，也就是模型文件的数据格式需要自己去解析。不同深度学习框架导出的模型权重文件格式都不一样，会涉及到比较底层的位读写。这里有一定工作量。</li>
<li>使用卷积神经网络预测模型的时候，会涉及到 padding，这部分需要自己计算。输出数据体在空间上的尺寸可以通过输入数据体尺寸（W），卷积层中神经元的感受野尺寸（F），步长（S）和零填充的数量（P）的函数来计算。输出数据体的空间尺寸为 (W-F +2P)/S+1。这里说的是某个维度，单指宽或长。</li>
<li><p><code>MPSImage</code> 是为了突破 <code>MTLTexture</code> 最大维度为 4 （RGBA）的限制，搞了个 workaround，就是用多个切片模拟多维度。如果有 N 个维度，那么切片数量为 (N+3)/4。比如下图为 N = 9 的情况。所以涉及到数据对齐的事情，预测后的数据需要处理下。</p>
<p> <img src="https://docs-assets.developer.apple.com/published/48ad0af3fd/b6d1d091-162c-418d-bc2e-0b6f3105c126.png" alt=""></p>
</li>
</ol>
<p>好在苹果提供的 Demo 里已经对于后两个问题有了可以参考的代码，第一个问题其实是个矩阵转换的操作。 TensorFlow 卷积核权重的顺序为 [kH kW iC oC]，而 MPS 接受的权重为 [oC kH kW iC] 形式。而我使用 Keras 的时候将 TensorFlow 作为后端，所以需要转换下权重格式。矩阵转换在 python 里很容易，还好我找到了 Swift 版本的实现：<a href="https://github.com/kazoo-kmt/MPSCNNfeeder/blob/master/swapaxes.swift" target="_blank" rel="external">SwapAxes</a>，直接拿过来用了。</p>
<blockquote>
<p>PS: 科普下，[oC kH kW iC] 是四维数组（矩阵） [outputChannels][kernelHeight][kernelWidth][inputChannels/groups] 的 shape。</p>
</blockquote>
<h3 id="使用-MPS-构建网络并预测"><a href="#使用-MPS-构建网络并预测" class="headerlink" title="使用 MPS 构建网络并预测"></a>使用 MPS 构建网络并预测</h3><p>MPS 预测的执行流程如下：</p>
<ol>
<li>获取可用的 device</li>
<li>从 <code>device</code> 获取 <code>commandQueue</code>，从 <code>commandQueue</code> 获取 <code>commandBuffer</code></li>
<li>构建网络模型和输入数据的 <code>MSPImage</code> 对象</li>
<li>调用网络每层的 <code>encode</code> 方法，输入为 <code>commandBuffer</code> 和上一层网络输出的 <code>MSPImage</code> 对象。</li>
<li>提交 <code>commandBuffer</code></li>
<li>等待输出结果，并处理成 one-hot 格式。</li>
</ol>
<p>剩下的工作就是修改工程中的 <code>Inception3Net.swift</code> 文件，使其网络结构与我们用 Keras 搭建的网络结构一样即可。前面提到过，<code>Flatten</code> 和 <code>Dropout</code> 没有权重，不改变数据。<code>Flatten</code> 其实就是 <code>reshape</code> 操作，在 MPS 中不需要特意做 <code>reshape</code> 操作也没有 <code>Flatten</code> 层，<code>MPSImage</code> 被描述成什么 shape，数据就会被排列成那个 shape。<code>Dropout</code> 层在训练的时候按一定几率丢弃结果，在预测模型的时候根本用不到。</p>
<p>回顾下之前用 Keras 写的全连接层结构的代码：</p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">model</span> = Sequential()</span><br><span class="line"><span class="keyword">model</span>.add(Flatten(input_shape=train_data.shape[<span class="number">1</span>:]))</span><br><span class="line"><span class="keyword">model</span>.add(Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line"><span class="keyword">model</span>.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line"><span class="keyword">model</span>.add(Dense(<span class="number">5</span>, activation=<span class="string">'softmax'</span>))</span><br></pre></td></tr></table></figure>
<p>转换成 MPS 的代码后差不多是这个样子（省略无关代码）：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">let device = inputCommandQueue.device</span><br><span class="line">let relu = MPSCNNNeuronReLU(<span class="string">device:</span> device!, <span class="string">a:</span> <span class="number">0</span>)</span><br><span class="line">let softmax = MPSCNNSoftMax(<span class="string">device:</span> device!)</span><br><span class="line">let sftid = MPSImageDescriptor(<span class="string">channelFormat:</span> textureFormat, <span class="string">width:</span> <span class="number">1</span>  , <span class="string">height:</span> <span class="number">1</span>  , <span class="string">featureChannels:</span> <span class="number">5</span>)</span><br><span class="line"><span class="comment">// logits</span></span><br><span class="line">let fc0 = SlimMPSCNNFullyConnected(<span class="string">kernelWidth:</span> <span class="number">8</span>,</span><br><span class="line"><span class="symbol">                             kernelHeight:</span> <span class="number">8</span>,</span><br><span class="line"><span class="symbol">                             inputFeatureChannels:</span> <span class="number">2048</span>,</span><br><span class="line"><span class="symbol">                             outputFeatureChannels:</span> <span class="number">256</span>,</span><br><span class="line"><span class="symbol">                             neuronFilter:</span> relu,</span><br><span class="line"><span class="symbol">                             device:</span> device,</span><br><span class="line"><span class="symbol">                             kernelParamsBinaryName:</span> <span class="string">"fc1"</span>)</span><br><span class="line">   </span><br><span class="line">let fc1 = SlimMPSCNNFullyConnected(<span class="string">kernelWidth:</span> <span class="number">1</span>,</span><br><span class="line"><span class="symbol">                             kernelHeight:</span> <span class="number">1</span>,</span><br><span class="line"><span class="symbol">                             inputFeatureChannels:</span> <span class="number">256</span>,</span><br><span class="line"><span class="symbol">                             outputFeatureChannels:</span> <span class="number">5</span>,</span><br><span class="line"><span class="symbol">                             neuronFilter:</span> nil,</span><br><span class="line"><span class="symbol">                             device:</span> device,</span><br><span class="line"><span class="symbol">                             kernelParamsBinaryName:</span> <span class="string">"fc2"</span>)</span><br><span class="line">...</span><br><span class="line">let image10 = ...</span><br><span class="line">let sftImage    = MPSImage(<span class="string">device:</span> device!, <span class="string">imageDescriptor:</span> sftid)</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment">// MPSImageDescriptor for final logits generating layers</span></span><br><span class="line">let fc0id = MPSImageDescriptor(<span class="string">channelFormat:</span> textureFormat, <span class="string">width:</span> <span class="number">1</span>, <span class="string">height:</span> <span class="number">1</span>, <span class="string">featureChannels:</span> <span class="number">256</span>)</span><br><span class="line">    </span><br><span class="line">var fc0Image, <span class="string">fc1Image :</span> MPSTemporaryImage!</span><br><span class="line">    </span><br><span class="line">func logits_layer(<span class="string">commandBuffer:</span> MTLCommandBuffer)&#123;</span><br><span class="line">   <span class="comment">// These images are only needed in this layer and will not be read by the CPU or</span></span><br><span class="line">   <span class="comment">// outside of the command bufer, so we can allocate them as MPSTemporaryImages and</span></span><br><span class="line">   <span class="comment">// save the CPU cost and memory size of allocating reserved storage for them.</span></span><br><span class="line">   <span class="comment">//</span></span><br><span class="line">   <span class="comment">// These objects can not be reused outside of the command buffer, which is why</span></span><br><span class="line">   <span class="comment">// we did not make them in the init(withDevice:commandQueue:) call.</span></span><br><span class="line">   <span class="comment">//</span></span><br><span class="line">   <span class="comment">// Temporary images are designed to be efficiently created as needed, used a few times</span></span><br><span class="line">   <span class="comment">// and thrown away almost immediately</span></span><br><span class="line">   </span><br><span class="line">   fc0Image     = MPSTemporaryImage(<span class="string">commandBuffer:</span> commandBuffer, <span class="string">imageDescriptor:</span> fc0id)</span><br><span class="line">   fc1Image     = MPSTemporaryImage(<span class="string">commandBuffer:</span> commandBuffer, <span class="string">imageDescriptor:</span> sftid)</span><br><span class="line">   </span><br><span class="line">   <span class="comment">// encode layers to metal commandBuffer</span></span><br><span class="line">   fc0.encode    (<span class="string">commandBuffer:</span> commandBuffer, <span class="string">sourceImage:</span> image10, <span class="string">destinationImage:</span> fc0Image)</span><br><span class="line">   fc1.encode    (<span class="string">commandBuffer:</span> commandBuffer, <span class="string">sourceImage:</span> fc0Image, <span class="string">destinationImage:</span> fc1Image)</span><br><span class="line">   softmax.encode(<span class="string">commandBuffer:</span> commandBuffer, <span class="string">sourceImage:</span> fc1Image, <span class="string">destinationImage:</span> sftImage)</span><br><span class="line">   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这是一篇行外人看不懂，行内人觉得水，我自己觉得收获满满的实践笔记。并没有花大量篇幅总结Machine Learning 的基础知识，也没有逐个讲述框架 API 的使用，更没有列一堆公式和数学定义。。。因为这种知识体系大而全的文章，网上不胜枚举，而且肯定比我总结的好。本着一个小白去探索世界的心态，把自己从理论学习到训练模型再到 iOS 上的预测的实践流程记录下来。很多枯燥耗时的学习 ML、TF 和配置环境的过程都省略掉了。</p>
<p>最后建议如果有条件的话，还是用配置较高的集群或者云服务来训练模型，节省程序员宝贵的时间。如果不能做到自己提出创新有效的网络模型，其实深度学习的大量工作就是调参、采集数据、看别人论文如何改参数和网络结构，然后等待机器训练结果。。。反复循环。。。</p>
<p>神经网络不是真的模拟出人脑的生物特征，CNN 跟人眼扫视世界或人脑辨别物体其实差很多，深度学习只是尽力让机器拟合出想要的结果罢了，离真正的人工智能还差远了。所以不要被铺天盖地的吹嘘洗脑了，一个 AlphaGo 就能又让一大堆所谓的科技媒体高潮出机器快要统治人类了，不要老想搞个大新闻！</p>
<p>深度学习发展很快，要学习的内容还有很多。学习得越多，就发现自己越是无知，以至于怀疑自己的智商和精力了。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://www.coursera.org/learn/machine-learning/home" target="_blank" rel="external">Coursera Machine Learning</a><br><a href="https://www.tensorflow.org" target="_blank" rel="external">TensorFlow</a><br><a href="http://keras-cn.readthedocs.io/en/latest/" target="_blank" rel="external">Keras 中文文档</a><br><a href="https://keras.io" target="_blank" rel="external">Keras Documentation</a><br><a href="http://image-net.org" target="_blank" rel="external">ImageNet</a><br><a href="https://www.kaggle.com" target="_blank" rel="external">kaggle</a><br><a href="http://cs231n.stanford.edu" target="_blank" rel="external">CS231n: Convolutional Neural Networks for Visual Recognition</a><br><a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="external">Convolutional Neural Networks (CNNs / ConvNets)</a><br><a href="http://machinethink.net/blog/convolutional-neural-networks-on-the-iphone-with-vggnet/" target="_blank" rel="external">Convolutional neural networks on the iPhone with VGGNet</a><br><a href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html" target="_blank" rel="external">Building powerful image classification models using very little data</a><br><a href="https://www.hdfgroup.org" target="_blank" rel="external">HDF Group</a><br><a href="https://developer.apple.com/reference/metalperformanceshaders" target="_blank" rel="external">MetalPerformanceShaders</a><br><a href="https://developer.apple.com/reference/accelerate/bnns" target="_blank" rel="external">BNNS</a><br><a href="https://github.com/aleph7/HDF5Kit" target="_blank" rel="external">HDF5Kit</a><br><a href="https://github.com/shu223/iOS-10-Sampler" target="_blank" rel="external">iOS-10-Sampler</a><br><a href="https://github.com/kazoo-kmt/MPSCNNfeeder" target="_blank" rel="external">MPSCNNfeeder</a></p>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/iOS/">iOS</a><a href="/tags/Machine-Leaning/">Machine Leaning</a><a href="/tags/Metal/">Metal</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	  <div data-url="http://yulingtianxia.com/blog/2017/05/30/Implementing-CNN-with-MPS/" data-title="Implementing CNN with MPS | yulingtianxia&#39;s blog" data-tsina="1680627603" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/blog/2017/06/19/Core-ML-and-Vision-Framework-on-iOS-11/" title="Core ML and Vision Framework on iOS 11">
  <strong>上一篇：</strong><br/>
  <span>
  Core ML and Vision Framework on iOS 11</span>
</a>
</div>


<div class="next">
<a href="/blog/2017/04/17/Objective-C-Method-Swizzling/"  title="Objective-C Method Swizzling">
 <strong>下一篇：</strong><br/> 
 <span>Objective-C Method Swizzling
</span>
</a>
</div>

</nav>

	

<section id="comments" class="comment">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>



</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目录</strong>
 
 <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#理论基础"><span class="toc-number">1.</span> <span class="toc-text">理论基础</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#卷积神经网络简介"><span class="toc-number">1.1.</span> <span class="toc-text">卷积神经网络简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#图片分类常用的数据和预设网络模型"><span class="toc-number">1.2.</span> <span class="toc-text">图片分类常用的数据和预设网络模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#迁移学习"><span class="toc-number">1.3.</span> <span class="toc-text">迁移学习</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#框架选择"><span class="toc-number">2.</span> <span class="toc-text">框架选择</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据采集"><span class="toc-number">3.</span> <span class="toc-text">数据采集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Inception-V3-pre-trained-network"><span class="toc-number">4.</span> <span class="toc-text">Inception V3 pre-trained network</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#bottleneck-features"><span class="toc-number">4.1.</span> <span class="toc-text">bottleneck features</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Fine-tuning"><span class="toc-number">4.2.</span> <span class="toc-text">Fine-tuning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Convert-HDF5-to-binary-dat-files"><span class="toc-number">5.</span> <span class="toc-text">Convert HDF5 to binary .dat files</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Metal-Performance-Shaders"><span class="toc-number">6.</span> <span class="toc-text">Metal Performance Shaders</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#MPS-简介"><span class="toc-number">6.1.</span> <span class="toc-text">MPS 简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#使用-MPS-构建网络并预测"><span class="toc-number">6.2.</span> <span class="toc-text">使用 MPS 构建网络并预测</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-number">7.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number">8.</span> <span class="toc-text">Reference</span></a></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  
<div class="github-card">
<p class="asidetitle">Github 名片</p>
<div class="github-card" data-github="yulingtianxia" data-theme="medium"></div>
<script type="text/javascript" src="//cdn.jsdelivr.net/github-cards/latest/widget.js" ></script>
</div>



  

  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="http://pbxproj.yulingtianxia.com" target="_blank" title="pbxprojHelper">pbxprojHelper</a>
            
          </li>
        
          <li>
            
            	<a href="http://similarimagehunter.yulingtianxia.com" target="_blank" title="SimilarImageHunter">SimilarImageHunter</a>
            
          </li>
        
          <li>
            
            	<a href="http://spiral.yulingtianxia.com" target="_blank" title="Spiral">Spiral</a>
            
          </li>
        
          <li>
            
            	<a href="http://coloratom.yulingtianxia.com" target="_blank" title="ColorAtom">ColorAtom</a>
            
          </li>
        
          <li>
            
            	<a href="http://fish.yulingtianxia.com" target="_blank" title="养小鱼的水塘">养小鱼的水塘</a>
            
          </li>
        
          <li>
            
            	<a href="http://resume.yulingtianxia.com" target="_blank" title="我的简历">我的简历</a>
            
          </li>
        
    </ul>
</div>

  
  <div class="tagcloudlist">
    <p class="asidetitle">标签云</p>
    <div class="tagcloudlist clearfix">
       <a href="/tags/ARC/" style="font-size: 10px;">ARC</a> <a href="/tags/Algorithm/" style="font-size: 13px;">Algorithm</a> <a href="/tags/App-Extensions/" style="font-size: 10px;">App Extensions</a> <a href="/tags/AppGroups/" style="font-size: 10px;">AppGroups</a> <a href="/tags/AppleScript/" style="font-size: 10px;">AppleScript</a> <a href="/tags/C/" style="font-size: 11px;">C</a> <a href="/tags/CocoaPods/" style="font-size: 10px;">CocoaPods</a> <a href="/tags/Core-Data/" style="font-size: 15px;">Core Data</a> <a href="/tags/GitHub/" style="font-size: 14px;">GitHub</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Machine-Leaning/" style="font-size: 11px;">Machine Leaning</a> <a href="/tags/Message-Forwarding/" style="font-size: 11px;">Message Forwarding</a> <a href="/tags/Messaging/" style="font-size: 10px;">Messaging</a> <a href="/tags/Metal/" style="font-size: 12px;">Metal</a> <a href="/tags/Objective-C/" style="font-size: 19px;">Objective-C</a> <a href="/tags/Octopress/" style="font-size: 10px;">Octopress</a> <a href="/tags/RAC/" style="font-size: 11px;">RAC</a> <a href="/tags/Reference-Counting/" style="font-size: 10px;">Reference Counting</a> <a href="/tags/Reverse-Engineering/" style="font-size: 11px;">Reverse Engineering</a> <a href="/tags/Runtime/" style="font-size: 17px;">Runtime</a> <a href="/tags/Social-Framework/" style="font-size: 10px;">Social Framework</a> <a href="/tags/SpriteKit/" style="font-size: 17px;">SpriteKit</a> <a href="/tags/Swift/" style="font-size: 18px;">Swift</a> <a href="/tags/UIKit-Dynamics/" style="font-size: 10px;">UIKit Dynamics</a> <a href="/tags/VPN/" style="font-size: 10px;">VPN</a> <a href="/tags/Xcode/" style="font-size: 14px;">Xcode</a> <a href="/tags/iCloud/" style="font-size: 10px;">iCloud</a> <a href="/tags/iOS/" style="font-size: 20px;">iOS</a> <a href="/tags/macOS/" style="font-size: 17px;">macOS</a> <a href="/tags/字体/" style="font-size: 10px;">字体</a> <a href="/tags/本地化/" style="font-size: 10px;">本地化</a> <a href="/tags/瞎折腾/" style="font-size: 11px;">瞎折腾</a> <a href="/tags/碰撞检测/" style="font-size: 10px;">碰撞检测</a> <a href="/tags/翻译/" style="font-size: 16px;">翻译</a> <a href="/tags/设计模式/" style="font-size: 14px;">设计模式</a> <a href="/tags/转载/" style="font-size: 10px;">转载</a>
    </div>
  </div>


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">新浪微博</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=1680627603&verifier=c09974f5&dpc=1"></iframe>
</div>


  

<div class="doubanshow">
<p class="asidetitle">豆瓣秀</p>
<div>
<script type="text/javascript" src="http://www.douban.com/service/badge/53279288/?show=collection&amp;n=12&amp;columns=3&amp;hidelogo=yes&amp;hideself=yes&amp;cat=book|movie" ></script>
</div>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Stay hungry, stay foolish <br/>
			Talk is cheap, show me the code.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		<a href="http://weibo.com/1680627603" target="_blank" class="icon-weibo" title="微博"></a>
		
		
		<a href="https://github.com/yulingtianxia" target="_blank" class="icon-github" title="github"></a>
		
		
		<a href="http://stackoverflow.com/users/2374982" target="_blank" class="icon-stack-overflow" title="stackoverflow"></a>
		
		
		<a href="https://twitter.com/yulingtianxia" target="_blank" class="icon-twitter" title="twitter"></a>
		
		
		<a href="https://www.facebook.com/yulingtianxia" target="_blank" class="icon-facebook" title="facebook"></a>
		
		
		<a href="https://www.linkedin.com/in/yulingtianxia" target="_blank" class="icon-linkedin" title="linkedin"></a>
		
		
		<a href="https://www.douban.com/people/53279288" target="_blank" class="icon-douban" title="豆瓣"></a>
		
		
		<a href="http://www.zhihu.com/people/yulingtianxia" target="_blank" class="icon-zhihu" title="知乎"></a>
		
		
		<a href="https://plus.google.com/106642427004837273341?rel=author" target="_blank" class="icon-google_plus" title="Google+"></a>
		
		
		<a href="mailto:yulingtianxia@gmail.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		
				<div class="cc-license">
          <a href="http://creativecommons.org/licenses/by-nc-nd/4.0" class="cc-opacity" target="_blank">
            <img src="/img/cc-by-nc-nd.svg" alt="Creative Commons" />
          </a>
        </div>
    

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2019 
		
		<a href="/about" target="_blank" title="杨萧玉">杨萧玉</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<div class="hoverqrcode clearfix"></div>',
  '<a class="overlay" id="qrcode"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);

  $('.hoverqrcode').hide();

  var myWidth = 0;
  function updatehoverqrcode(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
    var qrsize = myWidth > 1024 ? 200:100;
    var options = {render: 'image', size: qrsize, fill: '#2ca6cb', text: url, radius: 0.5, quiet: 1};
    var p = $('.article-share-qrcode').position();
    $('.hoverqrcode').empty().css('width', qrsize).css('height', qrsize)
                          .css('left', p.left-qrsize/2+20).css('top', p.top-qrsize-10)
                          .qrcode(options);
  };
  $(window).resize(function(){
    $('.hoverqrcode').hide();
  });
  $('.article-share-qrcode').click(function(){
    updatehoverqrcode();
    $('.hoverqrcode').toggle();
  });
  $('.article-share-qrcode').hover(function(){}, function(){
      $('.hoverqrcode').hide();
  });
});   
</script>




<script type="text/javascript">

var disqus_shortname = 'yulingtianxia';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>








<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->

<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-49704553-1', 'auto');  
ga('send', 'pageview');
</script>



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?b5cb508df15ee6247a8c32c64eadb075";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
</html>
